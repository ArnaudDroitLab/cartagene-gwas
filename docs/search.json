[
  {
    "objectID": "CARTaGENE-GWAS-Report.html",
    "href": "CARTaGENE-GWAS-Report.html",
    "title": "\n1  Main GWAS pipeline\n",
    "section": "",
    "text": "1.1 Reproduce the pipeline and questions to address",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Main GWAS pipeline</span>"
    ]
  },
  {
    "objectID": "CARTaGENE-GWAS-Report.html#reproduce-the-pipeline-and-questions-to-address",
    "href": "CARTaGENE-GWAS-Report.html#reproduce-the-pipeline-and-questions-to-address",
    "title": "\n1  Main GWAS pipeline\n",
    "section": "",
    "text": "1.1.1 Two-step pipeline\nAssuming PCA components have already been computed (report to Section 1.3.2.1 and Section 1.3.2.2 for details), follow this two-step protocol:\n\nRetrieve all known variants associated with your genes of interest in Section 1.3.4, and generate the corresponding VCF file.\nChange the response variable to predict in Listing 1.5 (with option --glm, the model applied should adjust automatically whether the outcome is binary or continuous).\n\n1.1.2 Reproducibility\nTwo command-lines tools are needed for reproducing the analyses and/or delivering new outcomes:\n\n\nplink2 for running most of the SNPs analyses.\n\nbcftools for extracting variants of interest in a given genomic region.\nDetails for installing from scratch these two CLI tools are reported in Section A.1.\n\nThe code, main results (figures and tables), along with reports, are versioned in an unique place, on GitHub:\n\n\nGitHub project: cartagene-gwas to version the code\nR project + renv() to create a reproducible and standalone computational environment.\n\n1.1.3 Important Questions to Address!!\n\nCheck Human reference genome assembly, see Section 1.3.4.1. Indeed, among the five genome arrays assembled in Section 1.3.2.1, most have been mapped against GRCh37 (hg19), but at least one has been mapped against the recent hg38 (GRCh38, 2013) version, report to page 38 in Pelletier (2022).\nWe definitely do not have the most recent version of CarTaGene (in the paper, around \\(30000\\) samples mentioned, against \\(19131\\) in my genotyping arrays database)\nWhy starting from BAM/BED/BIM pre-processed files in Section 1.3.2.1, instead of FASTQ files available in /mnt/projects_tn01/Cartagene/data/merged? Related question: we use the BAM/BED/BIM files stored in folder /mnt/projects_tn01/Cartagene/analyses/QC for PCA computation in Section 1.3.2.2, but VCF files stored in /mnt/projects_tn01/Cartagene/analyses/variants_extraction for running the GWAS analyses, for which reason?\n\nWhy use a biased gene-centric approach, instead of true GWAS (further discussed in Section 1.4.4)?. If ou really want to use a candidate-gene approach, report to A current guide to candidate gene association studies, from David (2021).\nRun sample size experiences prior to gene candidate studies, see Section 2.3.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Main GWAS pipeline</span>"
    ]
  },
  {
    "objectID": "CARTaGENE-GWAS-Report.html#introduction",
    "href": "CARTaGENE-GWAS-Report.html#introduction",
    "title": "\n1  Main GWAS pipeline\n",
    "section": "\n1.2 Introduction",
    "text": "1.2 Introduction\n\n1.2.1 GWAS Litterature Review\n\nFundamental paper, aka Genome-wide association studies: theoretical and practical concerns, from Wang et al. (2005).\nBook reviewing pros and cons of statistical GWAS approaches, from Overview of Statistical Methods for Genome-Wide Association Studies, from Hayes (2013).\nGenome-wide association studies, from Uffelmann et al. (2021).\n\n1.2.2 Design of the CARTaGENE study\n\n\nCohort profile of the CARTaGENE study: Quebec’s population-based biobank for public health and personalized genomics, from Awadalla et al. (2013):\n\nIncludes both Single nucleotide polymorphisms (SNPs) and insertion-deletion (InDels).\n\n\n\n\n1.2.2.1 Impute unobserved GWAS in CARTaGENE\n\n\nMost of the CARTaGENE samples are WES (whole exome sequencing), instead of WGS (whole genome sequencing).\n\nÉvaluation de l’imputation des données génétiques Canadiennes-Françaises, from Pelletier (2022). Key points1:\n\nChapter 3, named “Evaluation of genetic imputation in the French-Canadian founder population”, pages 54-93. Details the underlying imputation strategy, derived from TOPMed (for Trans-Omics for Precision Medicine).\nPage 45/61: Describes imputation strategies, along with the preprocessing steps. Code for reproducing the analyses is FC-imputation. Imputation performance is much lower for SNPs exhibiting MAF&lt;0.01, strongly promoting early removal of rare variants:\nPage 83/99: Strong polymorphism in some regions, such as HLA.\n\n\n\n\n\n\n\n\n\nFigure 1.1: GWAS of CarTaGene SNPs using TOPMed Merge-Impute strategy. The TOPMed Imputation Server has been used. Manhattan plots depict the genome-wide association study (GWAS) results for variants, before and after imputation The figure is reproduced from (Pelletier 2022, 97–98). The \\(y\\)-axis represents the \\(-\\log_{10}(p)\\) \\(p\\)-value association of each variant. Variants with -values equal to zero are highlighted in green, while the horizontal red line indicates the genome-wide significance threshold.. The total sample consisted of \\(27,422\\) individuals, with the GWAS focus being comparing ground-truth SNPs versus imputed SNPs.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Main GWAS pipeline</span>"
    ]
  },
  {
    "objectID": "CARTaGENE-GWAS-Report.html#analyses",
    "href": "CARTaGENE-GWAS-Report.html#analyses",
    "title": "\n1  Main GWAS pipeline\n",
    "section": "\n1.3 Analyses",
    "text": "1.3 Analyses\n\n1.3.1 Setup enviroment\n\n1.3.1.1 Bash configuration:\nWe use symbolic links to encapsulate the whole project, see ln -s Post for details:\n\nCode## Render executive files findable\nexport PATH=./bin/bcftools/bin:$PATH\nexport PATH=./bin/plink2:$PATH\n\n## Check versions\nplink2 --version\necho -e \"\\n\"\nbcftools --version\n\n## Create symbolic links to organise everything within the same folder\n## warning: if original content is deleted, everything broke!!!!!!\necho ln -s ./data/genotypages/ /mnt/projects_tn01/Cartagene/genotypage/imputation/imputation_merged\n\n##  PLINK v2.0.0-a.6.9LM 64-bit Intel (29 Jan 2025)\n##  \n##  \n##  bcftools 1.21\n##  Using htslib 1.21\n##  Copyright (C) 2024 Genome Research Ltd.\n##  License Expat: The MIT/Expat license\n##  This is free software: you are free to change and redistribute it.\n##  There is NO WARRANTY, to the extent permitted by law.\n##  ln -s ./data/genotypages/ /mnt/projects_tn01/Cartagene/genotypage/imputation/imputation_merged\n\n\n\n1.3.1.2 R configuration:\n\nCode## data wrangling and visualisations\nlibrary(haven)\nlibrary(flextable)\nlibrary(dplyr)\nlibrary(ggplot2)\n## Required for code linking\nlibrary(downlit)\nlibrary(xml2)\n\n# Avoid warning \"Replace previous import ‘utils::findMatches’ by ‘S4Vectors::findMatches’ when loading ‘AnnotationDbi’\"\nlibrary(conflicted)\nconflicted::conflict_prefer(\"findMatches\", \"S4Vectors\")\nconflicted::conflicts_prefer(base::setdiff, base::intersect, \n                             base::setequal, base::union)\nconflicted::conflicts_prefer(dplyr::select, dplyr::filter)\n\n\n## Retrieve gene positions\nlibrary(GenomicFeatures) # Pre-load the package for mapping gene IDs\nlibrary(org.Hs.eg.db)  ## Provides gene symbol to Entrez ID mapping\n\n## for generating nice visualisations\nsource(\"R/gwas_plots.R\")\n\n\n\n1.3.2 Compute PCA loadings\n\n\n1.3.2.1 Step 1: Merge genotype arrays\nGenotypes were split into five different genotyping arrays. Arrays were merged together using Bash script merge_datasets.sh, and command --bmerge of tool plink2. This command only keeps matching SNPs and alleles across the 5 arrays.\nThe resulting BAM files (sequence alignments), BED files (genomic regions of interest, for viewers), BIM (SNP information) and FAM (phenotype data, such as individuals and pedigree), are listed in folder /mnt/projects_tn01/Cartagene/analyses/QC, with prefix merge_5_* (for 5 genotypes concatenated).\n\n1.3.2.2 Step 2: Preprocessing for Removing Correlated Features\nRemark: the prefix eur_only stands for Caucasian phenotypes.\n\n1.3.2.2.1 i) Trim missing SNPs\n\n\nInputs:\n\n\nPhenotype Ids of white individuals: eur_only/cartagene_self_reported_EUR.plink_format.txt\n\n\nBIM/BED/FAM/hh folder generated with --make-bed command: analyses/QC/merge_5_datasets. It seems that among the 5 genotype arrays concatenated, at least one genotype, namely gsa.17k.final.hg19.bim, has been mapped thanks to GRCh37 (hg19) reference instead of more recent hg38 (GRCh38, 2013) version.$$\n\n\nObjective: Keep white individuals and remove SNPs variants with genotyping rate \\(&lt;0.95\\). The genotyping rate measures the proportion of successfully genotyped markers and indicates how complete the genotype data is. Removing SNPs with low Genotyping Rate increases Missing Data imputation performance, and overall maintains higher statistical power.\nRemark: Also advised to exclude samples with low Genotyping Rate, below 0.98.\nBash command:\n\nplink2 \\\n  --bfile /mnt/projects_tn01/Cartagene/analyses/QC/merge_5_datasets \\\n  --geno 0.05 \\\n  --keep /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/cartagene_self_reported_EUR.plink_format.txt \\\n  --make-bed \\\n  --out /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095\n\n1.3.2.2.2 ii) Hardy-Weinberg Disequilibrium\n\n\nInputs:\n\n\nBIM/BED/FAM/hh (Homozygous-Haplotype) files generated from previous SNP missing removal, see Section 1.3.2.2.1.\n\n\nObjective: Remove SNPs variants with Hardy-Weinberg disequilibrium \\(&lt; 1 \\times 10^{-6}\\). Indeed, if a SNP is in HWD, it might reflect hidden sub-population structure or poor-quality rather than true genetic associations.\nRemark: If a SNP is under strong natural selection, such as SNPs involved in the HLA genes, they are likely to deviate from HWE due to balancing selection. If the SNP is biologically important, don’t exclude it blindly!! Alternative: compute the SNP score.\nBash command:\n\nplink2 \\\n  --bfile /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095 \\\n  --hwe 1e-6 \\\n  --make-bed \\\n  --out /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06\n\n1.3.2.2.3 iii) Linkage Disequilibrium\n\n1.3.2.2.3.1 Local LD analysis\n\n\nInputs:\n\n\nBIM/BED/FAM/hh (Homozygous-Haplotype) files /merge_5_datasets.eur_only.geno095.hwe1e0 generated from previous HWD SNP trimming, see Section 1.3.2.2.2.\n\n\nObjective: Remove SNPs variants associated with strong linkage disequilibrium. In an ideal population under random mating, allele combinations should be independent (\\(r^2=0\\)). However, due to factors such as genetic drift, or physical proximity, certain alleles tend to be inherited together more often than expected. In GWAS, LD pruning avoids overfitting (SNPs in high LD carry redundant information), avoiding spurious inflation of GWAS association signals.\nRemark: Report the Number of SNPs Before and After Pruning, usually more stringent \\(R^2\\) is considered.\nTool: plink --indep-pairwise 50 5 0.5 will discard SNPs with a correlation coefficient above \\(0.5\\) (given that a \\(R^2\\) score of 1 indicates a perfect correlation), on a rolling window of \\(50\\) SNPs (focus on local zones) and step \\(5\\) by \\(5\\).\nBash command:\n\n## identify SNPs with low LD\nplink2 \\\n  --bfile /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06 \\\n  --indep-pairwise 50 5 0.5 \\\n  --out /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps\n  \n## save pruned SNPs associated with low LD\nplink2 \\\n  --bfile /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06 \\\n  --extract /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps.prune.in \\\n  --make-bed \\\n  --out /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps_bfile\n\n1.3.2.2.3.2 Global LD analysis from prior expert knowledge\n\n\nInputs:\n\n\nBIM/BED/FAM/hh (Homozygous-Haplotype) files merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps_bfile generated from previous local LD trimming, see Section 1.3.2.2.3.1.\n\n\nObjective: Remove SNPs variants associated with strong linkage disequilibrium using prior expert knowledge, see here for details.2\n\n\n\nBash command:\n\n\nplink2 \\\n  --bfile /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps_bfile \\\n  --exclude range /mnt/projects_tn01/Cartagene/analyses/QC/high_ld_regions.plink_format.txt \\\n  --make-bed \\\n  --out /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps.high_LD_excluded\n\n1.3.2.2.4 iv) Exclude affiliated individuals based on high IBD scores\n\n\nInputs:\n\n\nBIM/BED/FAM/hh (Homozygous-Haplotype) files merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps_bfile generated from previous local LD trimming, see Section 1.3.2.2.3.1.\n\n\nObjective: Exclude related individuals computing identity by descent (IBD), a genetic metric of the relatedness between two individuals, and exclude one individual by pairs of individuals with a score above \\(0.2\\). Indeed, strongly associated patients increase bias in GWAS, raising a stronger score than expected in the general population, and prevents quality controls to detect duplicates or sample mix-ups.\nDetails: A two-step, more stringent IBD filtering strategy has been chosen, eliminating first the most problematic individuals, and the second ensuring the remaining related individuals are properly filtered (for each correlated pair, prune randomly one of them). The Bash instructions are reported here.\nRemarks: Choice of a heuristic threshold of \\(n=68\\) affiliated patients removal to be further discussed. Current score of PI_HAT score of \\(0.2\\) is surprising, as common thresholds are either \\(0.25\\) for discarding grandparent-grandchild, or \\(0.125\\) or lower for only keeping the most distant relatives. Starting from PLINK 2.0, the recommended approach is now utilizing the --king-cutoff command, over the older --rel-cutoff and --genome --min + aggregates all subsequent steps simultaneously, especially in heterogeneous populations3.\nBash command:\n\n\n## Calculate IBD, select individuals with IBD above 0.2 for further pruning\n\nplink2 \\\n  --bfile /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps_bfile \\\n  --genome \\\n  --memory 12006 \\\n  --min 0.2 \\\n  --out /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps.IBD\n\n\n## Remove related individuals, in a two-stage process\n\nplink2 \\\n  --bfile /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps_bfile \\\n  --make-bed \\\n  --out /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps_bfile.rem_rel_ind_round_1_of_2 \\\n  --remove /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/related_ids/IBD.genome.iids.merged.sorted.count.reverse.ids_related_to_2_individuals.ids_only.FID_IID_format\n\n\nplink2 \\\n  --bfile /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps_bfile.rem_rel_ind_round_1_of_2 \\\n  --make-bed \\\n  --out /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps_bfile.rem_rel_ind_round_2_of_2 \\\n  --remove /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/related_ids/IBD.genome2.related_individuals_to_remove.txt \n\n1.3.2.3 Step 3: PCA Computation and Population Genetic Evaluation\n\n\nInputs:\n\n\nBIM/BED/FAM/hh (Homozygous-Haplotype) files merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps.high_LD_excluded resulting from the pre-processing operations reported in Section 1.3.2.2 (LD, HWD and missing SNPs trimming)\n\nphenotype IDs listed in merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps_bfile.rem_rel_ind_round_2_of_2, where all affiliated patients have been removed.\n\n\nObjective: Compute PCA and keep the 10 first principal components.\nBash command:\n\n\nplink2 \\\n  --bfile /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps.high_LD_excluded \\ \n  --keep merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps_bfile.rem_rel_ind_round_2_of_2.fam \\\n  --memory 12006 \\\n  --out /mnt/projects_tn01/Cartagene/analyses/QC/eur_only/merge_5_datasets.eur_only.geno095.hwe1e06.pruned_snps.high_LD_excluded.unrelated_ind.PCA \\\n  --pca 10\n\n\nRemarks:\n\nRemark 1: use visualizations, such as scree plots, elbow point or/and Tracy-Widom Test to select the final number of PCs, instead of hard threshold, and on the other hand, scatter plots to identify latent structures. See details here and there.\nRemark 2: The popgen ‘Calculating Basic Population Genetic Statistics from SNP Data’ vignette details how to generate statistics quantifying patterns of genetic diversity, such as LD and Hardy-Weinberg, in a given population. The popgen ‘Calculating genetic differentiation and clustering methods from SNP data’ vignette vignette describes both unsupervised, PCA-like and discriminatory approaches to identify latent genetic sub-populations.\nFinally, the popgen ‘Individual Based Genetic Distance for SNP Data’ vignette reports different individual genetic distances, enabling to spot and trim individual outliers with a significant distinct genetic distribution. See also paper ‘A benchmark study on current GWAS models in admixed populations’, from Yang et al. (2024) for an unbiased and up-to-date comparison of statistical approaches to address within-patient heterogeneity.\nRemark 3: To evaluate within-population diversity, geneticists typically report the level of heterozygosity as a general metric, see vcfR‘Genetic differentiation’ Vignette.\n\n\n\n1.3.3 Run GWAS analyses\n\n1.3.3.1 Step 1: Phenotype feature extraction\nOriginal phenotype annotations are available in folder /mnt/projects_tn01/Cartagene/analyses/phenotypes. Variables of interest are reported here:\n\nCodecartagene_response_variables &lt;- readxl::read_excel(\"data/phenotypes/cartagene_response_variables.xlsx\")\n\n\n\n1.3.3.1.1 i) Merge genotype IDs, phenotypes and PCAs values\nGeneral phenotype features are provided in\n\nCodecartagene_phenodata &lt;- haven::read_sas(\"data/phenotypes/cart_mars2025.sas7bdat\")\nflextable(head(cartagene_phenodata)) |&gt; \n  bold(bold = TRUE, part = \"header\")\n\n\n\n\n\n\n\nPROJECT_CODE\nASA\nSTATINE\nAge (decimal)\nCKD_EPI\nBody Mass Index (BMI)\nT-Score\nBPS\nSRAAI\nGENDER01\nETHNICITY6M\nTABACCOURANT_M\nROHSEMAINE\nDIABETEGLOBAL\nDLPGLOBAL\nHTAGLOBAL\nASTHME_MPOCAUTO_RX\nCIRRHOSEAUTO_M\nOSTEOAUTO_M\nOSTEORX\nNEOALL_AUTO_M\nNEOCHIMIO_AUTO_M\nNEORADIO_AUTO_M\nOSTEOSECONDAIRE\nCVMACE_POST\nCVMACE_PROCEDURE_POST\nCVALL_POST\nCVALL_POSTDATE\nCVMACE_POSTDATE\nCVMACE_PROCEDURE_POSTDATE\nDECES\nDATEDECES1216\nFXALL_POST\nFXALL_PRE1\nFXALL_PRE5\nFXMOF_POST\nFXALL_POSTDATE\nFXMOF_POSTDATE\nAVCGLOBAL_PRE_M\nATCDFAMCV\nHRT\nIRC\nPWV1\nMCASGLOBAL_PRE_M\n\n\n\n78,295,800,001\n1\n1\n62.08\n56.60608\n\n1.7\n0\n0\n0\nBlanc\n0\n0.25\n0\n1\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n2,228\n2,228\n2,228\n0\n\n0\n0\n0\n0\n2,228\n2,228\n0\n0\n0\n1\n10.293434\n1\n\n\n78,295,800,002\n0\n0\n43.84\n77.58291\n35.4\n3.2\n0\n0\n1\nLatin\n0\n0.00\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n236\n2,059\n236\n0\n\n0\n0\n0\n0\n2,059\n2,059\n0\n0\n0\n0\n6.110750\n0\n\n\n78,295,800,003\n0\n0\n59.27\n86.25898\n22.7\n-2.3\n0\n0\n1\nBlanc\n0\n8.00\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n2,205\n2,205\n2,205\n0\n\n0\n0\n0\n0\n2,205\n2,205\n0\n0\n0\n0\n8.271314\n0\n\n\n78,295,800,004\n1\n0\n58.52\n85.17528\n23.5\n-1.8\n1\n0\n1\nBlanc\n0\n0.00\n0\n1\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n2,184\n2,184\n2,184\n0\n\n0\n0\n0\n0\n2,184\n2,184\n0\n0\n1\n0\n8.810156\n0\n\n\n78,295,800,005\n0\n0\n54.92\n105.51846\n30.3\n1.1\n0\n0\n0\nBlanc\n0\n4.50\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n2,103\n2,103\n2,103\n0\n\n0\n0\n0\n0\n2,103\n2,103\n0\n1\n0\n0\n8.310378\n0\n\n\n78,295,800,006\n0\n0\n45.06\n113.30294\n28.2\n-1.2\n0\n0\n1\nArabe\n0\n0.00\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n2,000\n2,000\n2,000\n0\n\n0\n0\n0\n0\n2,000\n2,000\n0\n0\n0\n0\n\n0\n\n\n\n\n\n\n\nTable 1.1: Read SAS table describing CarTaGene phenotypes.\n\n\n\nNumber of patients overall is 19990, and number of phenotype variables is 44.\nWe then need to map each individual patient ID (IID) with its corresponding genotype array Table 1.2, as done in Listing 1.1.\n\nCodecartagene_genotypes_ID &lt;- readr::read_csv2(\"./data/phenotypes/cartagene_genotype_IDs.csv\",\n                                           show_col_types = FALSE, \n                                           col_types = c(\"d\", \"c\",\"c\")) |&gt; \n  dplyr::rename(PROJECT_CODE = \"project_code\", geno_id = \"file_111\", batch=\"batch\")\n  \n\nflextable(head(cartagene_genotypes_ID)) |&gt; \n  bold(bold = TRUE, part = \"header\")\n\n\n\n\n\n\n\nPROJECT_CODE\ngeno_id\nbatch\n\n\n\n78,295,800,001\n11,118,538\ngsa.17k\n\n\n78,295,800,002\n11,135,721\ngsa.17k\n\n\n78,295,800,003\n11,129,497\ngsa.archi.withIBS\n\n\n78,295,800,004\n11,107,817\ngsa.17k\n\n\n78,295,800,005\n11,131,634\ngsa.archi.withIBS\n\n\n78,295,800,006\n11,126,455\ngsa.17k\n\n\n\n\n\n\n\nTable 1.2: Read SAS table describing CarTaGene phenotypes.\n\n\n\n\n\n\nListing 1.1: Inner join between phenotypes IDs and genotypes, while constraing the remaining individuals to belong to white ethnicity.\n\ncartagene_phenodata &lt;- cartagene_phenodata |&gt; \n  dplyr::inner_join(cartagene_genotypes_ID, by=\"PROJECT_CODE\") |&gt; \n  dplyr::filter(ETHNICITY6M==\"Blanc\")\n\n\n\n\nThe resulting phenotype table, after joining with genotypes IDs and restraining to Eurasian phenotypes, stores 17147 individuals.\nPCA vectors computed in Section 1.3.2.3 are subsequently merged with phenotype data in Listing 1.2.\n\n\n\nListing 1.2: Inner join between phenotypes IDs and first 10 PCA eigen vectors.\n\nPCs &lt;- readr::read_delim(\"data/PCAs/PCA_eigenvec\",\n                        col_names = c(\"FID\", \"geno_id\", \"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\", \"PC10\"), \n                        delim = \" \",\n                        show_col_types = FALSE)\ncartagene_phenodata &lt;- PCs |&gt; \n  dplyr::inner_join(cartagene_phenodata, by=\"geno_id\") |&gt; \n  dplyr::rename(IID = geno_id)\n\n\n\n\n\nRemark: Avoid using French CSV settings, switch to universal convention, where delimiter is a comma: ,\n\n1.3.3.1.2 ii) Bone damage: osteoporosis and fractures\n\n\nThe response variables OSTEOPONIA and OSTEOPOROSIS have been computed following these rules Listing 1.3, with the resulting contingency tables reported in Table 1.3.\n\nExclude patients with osteosecondaire==1.\n\nOSTEOPONIA is case: 1 if DMOTSCORE_mod &lt;= -1.5 and control elsewhere4.\n\nOSTEOPOROSIS is case: 1 if DMOTSCORE_mod &lt; -2.5 and control elsewhere. DMOTSCORE_mod has been likely Gaussian standardised + lacks of evidence supporting clear multi-modal distributions. Is there a reporting of the pre-processing operations?.\n\n\n\n\n\n\nListing 1.3: Generate scores of interest.\n\ncartagene_phenodata &lt;- cartagene_phenodata |&gt; \n  dplyr::mutate(DMOTSCORE_mod = dplyr::if_else(OSTEOSECONDAIRE ==1, NA, DMOTSCORE), \n                OSTEOPONIA = dplyr::case_when(DMOTSCORE_mod &lt;= -1.5 ~ 1, \n                                              DMOTSCORE_mod &gt; -1.5 ~ 0, \n                                              .default = NA),\n                OSTEOPOROSIS = dplyr::case_when(DMOTSCORE_mod &lt; -2.5 ~ 1, \n                                              DMOTSCORE_mod &gt;= -2.5 ~ 0, \n                                              .default = NA)) \n  \n\nflextable::proc_freq(cartagene_phenodata, \n                     \"OSTEOPONIA\", \"OSTEOPOROSIS\")\n\n\n\n\n\n\n\n\n\n\n\nOSTEOPONIA\n\nOSTEOPOROSIS\n\n\n0\n1\nMissing\nTotal\n\n\n\n\n0\nCount\n12,463 (74.8%)\n\n\n12,463 (74.8%)\n\n\nMar. pct (1)\n94.3% ; 100.0%\n\n\n\n\n\n1\nCount\n753 (4.5%)\n48 (0.3%)\n\n801 (4.8%)\n\n\nMar. pct\n5.7% ; 94.0%\n100.0% ; 6.0%\n\n\n\n\nMissing\nCount\n\n\n3,393 (20.4%)\n3,393 (20.4%)\n\n\nMar. pct\n\n\n100.0% ; 100.0%\n\n\n\nTotal\nCount\n13,216 (79.3%)\n48 (0.3%)\n3,393 (20.4%)\n16,657 (100.0%)\n\n\n (1) Columns and rows percentages\n\n\n\n\n\nTable 1.3: OSTEOPOROSIS is considered as more severe than OSTEOPONIA, hence the striclty lower number of individuals affected by the disease.\n\n\n\n\n\nFracture events:\n\nWe merge FXALL_PRE5 (any fracture occurring within the five years prior to recruitment) with FXALL_POST (all fractures occurring during follow-up) into variable FXALL, being positive if an event fracture occured prior or posterior. Which variable between FXALL_PRE5 and FXALL_PRE1 should be considered? Variables differ by 471 \\(\\%\\) overall!!\n\n\nFXMOF_POST (only osteoporotic fractures during follow-up)5 In contrast with labelling, osteoporotic events, as stored in FXMOF_POST, contain both pre-, and post- fracture events, as shown by Figure 1.2.\n\n\n\n\nCodecartagene_phenodata &lt;- cartagene_phenodata |&gt; \n  mutate(FXALL = dplyr::if_else(FXALL_POST == 1L | FXALL_PRE1 ==1L, 1L, 0L))\n\nflextable::proc_freq(cartagene_phenodata, \n                     \"FXALL\", \"FXMOF_POST\")\nflextable::proc_freq(cartagene_phenodata, \n                     \"FXALL_POST\", \"FXALL_PRE1\")\n\n\n\n\n\n\n\n\n\n\n\n\nFXALL\n\nFXMOF_POST\n\n\n0\n1\nTotal\n\n\n\n\n0\nCount\n15,824 (95.0%)\n\n15,824 (95.0%)\n\n\nMar. pct (1)\n96.8% ; 100.0%\n\n\n\n\n1\nCount\n529 (3.2%)\n304 (1.8%)\n833 (5.0%)\n\n\nMar. pct\n3.2% ; 63.5%\n100.0% ; 36.5%\n\n\n\nTotal\nCount\n16,353 (98.2%)\n304 (1.8%)\n16,657 (100.0%)\n\n\n (1) Columns and rows percentages\n\n\n\n\n\n(a) All fractures vs osteporotic fractures\n\n\n\n\n\n\n\n\n\n\n\n\nFXALL_POST\n\nFXALL_PRE1\n\n\n0\n1\nTotal\n\n\n\n\n0\nCount\n15,824 (95.0%)\n92 (0.6%)\n15,916 (95.6%)\n\n\nMar. pct (1)\n95.6% ; 99.4%\n82.9% ; 0.6%\n\n\n\n1\nCount\n722 (4.3%)\n19 (0.1%)\n741 (4.4%)\n\n\nMar. pct\n4.4% ; 97.4%\n17.1% ; 2.6%\n\n\n\nTotal\nCount\n16,546 (99.3%)\n111 (0.7%)\n16,657 (100.0%)\n\n\n (1) Columns and rows percentages\n\n\n\n\n\n(b) Pre vs post-fractures.\n\n\n\n\n\n\nTable 1.4: Description of fracture events.\n\n\n\n\n\n\n\n\n\n\n\n(a) Generated by VennDiagram\n\n\n\n\n\n\n\n\n\n(b) Generated by ggVennDiagram\n\n\n\n\n\n\nFigure 1.2: Venn Diagrams of fracture events, before and after diagnosis control.\n\n\n\n1.3.3.1.3 iii) Cardiovascular diseases\n\n\nThe variables CVALL_POST and CVMACE_POST correspond to the occurrence of any cardiovascular event and major adverse cardiovascular events (MACE), including myocardial infarction, stroke, or cardiovascular death events, is the cognate subset of the most life-threatening heart conditions. An extended follow-up dataset is available for CVALL_POST; however, it is not currently accessible.\nThe variable MCASGLOBAL_PRE_M captures ischemic heart disease events, at baseline.\nThe variable AVCGLOBAL_PRE_M represents the history of stroke events.\n\nContingency tables of both pre-, and post-, cardiovascular events are reported in Table 1.5.\nCodeflextable::proc_freq(cartagene_phenodata, \n                     \"CVALL_POST\", \"CVMACE_POST\")\nflextable::proc_freq(cartagene_phenodata, \n                     \"MCASGLOBAL_PRE_M\", \"AVCGLOBAL_PRE_M\")\n\n\n\n\n\n\n\n\n\n\n\n\nCVALL_POST\n\nCVMACE_POST\n\n\n0\n1\nTotal\n\n\n\n\n0\nCount\n16,215 (97.3%)\n\n16,215 (97.3%)\n\n\nMar. pct (1)\n98.7% ; 100.0%\n\n\n\n\n1\nCount\n221 (1.3%)\n221 (1.3%)\n442 (2.7%)\n\n\nMar. pct\n1.3% ; 50.0%\n100.0% ; 50.0%\n\n\n\nTotal\nCount\n16,436 (98.7%)\n221 (1.3%)\n16,657 (100.0%)\n\n\n (1) Columns and rows percentages\n\n\n\n\n\n(a) CVALL_POST vs CVMACE_POST\n\n\n\n\n\n\n\n\n\n\n\n\nMCASGLOBAL_PRE_M\n\nAVCGLOBAL_PRE_M\n\n\n0\n1\nTotal\n\n\n\n\n0\nCount\n15,520 (93.2%)\n203 (1.2%)\n15,723 (94.4%)\n\n\nMar. pct (1)\n94.8% ; 98.7%\n72.0% ; 1.3%\n\n\n\n1\nCount\n855 (5.1%)\n79 (0.5%)\n934 (5.6%)\n\n\nMar. pct\n5.2% ; 91.5%\n28.0% ; 8.5%\n\n\n\nTotal\nCount\n16,375 (98.3%)\n282 (1.7%)\n16,657 (100.0%)\n\n\n (1) Columns and rows percentages\n\n\n\n\n\n(b) MCASGLOBAL_PRE_M vs AVCGLOBAL_PRE_M\n\n\n\n\n\n\nTable 1.5: Cardiovascular disease events\n\n\nFinally, we save the updated phenotype dataset as a Tab-separated file, using readr::write_tsv, see Table 1.6 for details:\n\nCode## define Boolean categorical variables\ncategorical_variables &lt;- cartagene_response_variables$Features[\n  cartagene_response_variables$Type == \"Boolean\"]\n\ncartagene_phenodata &lt;- cartagene_phenodata |&gt;\n  dplyr::mutate(dplyr::across(dplyr::all_of(categorical_variables),\n                              \\(x) dplyr::if_else(x == 0L, 1L, 2L, missing = NA)))\nreadr::write_tsv(cartagene_phenodata, \n                 file=\"data/phenotypes/merge_phenos_PCs.txt\")\n\n\n# Report overall summaries\ncartagene_phenodata_summary &lt;- cartagene_phenodata |&gt; \n  dplyr::select(dplyr::all_of(c(\"IID\", \"GENDER01\", categorical_variables))) |&gt; \n  tidyr::pivot_longer(-dplyr::all_of(c(\"IID\", \"GENDER01\")), \n                      names_to = \"Features\", values_to = \"Value\") |&gt; \n  dplyr::mutate(Value = tidyr::replace_na(as.character(Value), \"osteosecondaire\")) |&gt; \n  dplyr::count(Features, GENDER01, Value) |&gt; \n  dplyr::rename(Counts=n) |&gt; \n  dplyr::inner_join(cartagene_response_variables, by = \"Features\") \n\n\n\ncartagene_phenodata_summary |&gt; \n  dplyr::filter(Disease == \"Bone Damage\") |&gt; \n  dplyr::select(Features, Description, GENDER01, Value, Counts) |&gt; \n  flextable() |&gt; \n  bold(part = \"header\")\ncartagene_phenodata_summary |&gt; \n  dplyr::filter(Disease == \"Cardiovascular events\") |&gt; \n  dplyr::select(Features, Description, GENDER01, Value, Counts) |&gt; \n  flextable() |&gt; \n  bold(part = \"header\")\n\n\n\n\n\n\n\n\nFeatures\nDescription\nGENDER01\nValue\nCounts\n\n\n\nFXALL\nAll fracture events\n0\n1\n7,640\n\n\nFXALL\nAll fracture events\n0\n2\n324\n\n\nFXALL\nAll fracture events\n1\n1\n8,184\n\n\nFXALL\nAll fracture events\n1\n2\n509\n\n\nFXMOF_POST\nRestriction to osteoporisis events\n0\n1\n7,857\n\n\nFXMOF_POST\nRestriction to osteoporisis events\n0\n2\n107\n\n\nFXMOF_POST\nRestriction to osteoporisis events\n1\n1\n8,496\n\n\nFXMOF_POST\nRestriction to osteoporisis events\n1\n2\n197\n\n\nOSTEOPONIA\nExclude osteosecondaire\n0\n1\n6,215\n\n\nOSTEOPONIA\nExclude osteosecondaire\n0\n2\n354\n\n\nOSTEOPONIA\nExclude osteosecondaire\n0\nosteosecondaire\n1,395\n\n\nOSTEOPONIA\nExclude osteosecondaire\n1\n1\n6,248\n\n\nOSTEOPONIA\nExclude osteosecondaire\n1\n2\n447\n\n\nOSTEOPONIA\nExclude osteosecondaire\n1\nosteosecondaire\n1,998\n\n\nOSTEOPOROSIS\nExclude osteosecondaire\n0\n1\n6,545\n\n\nOSTEOPOROSIS\nExclude osteosecondaire\n0\n2\n24\n\n\nOSTEOPOROSIS\nExclude osteosecondaire\n0\nosteosecondaire\n1,395\n\n\nOSTEOPOROSIS\nExclude osteosecondaire\n1\n1\n6,671\n\n\nOSTEOPOROSIS\nExclude osteosecondaire\n1\n2\n24\n\n\nOSTEOPOROSIS\nExclude osteosecondaire\n1\nosteosecondaire\n1,998\n\n\n\n\n\n\n\n\n\n\n\n\nFeatures\nDescription\nGENDER01\nValue\nCounts\n\n\n\nAVCGLOBAL_PRE_M\nPre General Critical Cardio event\n0\n1\n7,805\n\n\nAVCGLOBAL_PRE_M\nPre General Critical Cardio event\n0\n2\n159\n\n\nAVCGLOBAL_PRE_M\nPre General Critical Cardio event\n1\n1\n8,570\n\n\nAVCGLOBAL_PRE_M\nPre General Critical Cardio event\n1\n2\n123\n\n\nCVALL_POST\nPost General Cardio event\n0\n1\n7,636\n\n\nCVALL_POST\nPost General Cardio event\n0\n2\n328\n\n\nCVALL_POST\nPost General Cardio event\n1\n1\n8,579\n\n\nCVALL_POST\nPost General Cardio event\n1\n2\n114\n\n\nCVMACE_POST\nPost General Critical Cardio event\n0\n1\n7,802\n\n\nCVMACE_POST\nPost General Critical Cardio event\n0\n2\n162\n\n\nCVMACE_POST\nPost General Critical Cardio event\n1\n1\n8,634\n\n\nCVMACE_POST\nPost General Critical Cardio event\n1\n2\n59\n\n\nMCASGLOBAL_PRE_M\nPre General Cardio event\n0\n1\n7,308\n\n\nMCASGLOBAL_PRE_M\nPre General Cardio event\n0\n2\n656\n\n\nMCASGLOBAL_PRE_M\nPre General Cardio event\n1\n1\n8,415\n\n\nMCASGLOBAL_PRE_M\nPre General Cardio event\n1\n2\n278\n\n\n\n\n\n\n\n\nTable 1.6: Features of interest to regress on SNPs in CarTaGene. Besides, recent versions of plink2 impose explicit encoding of categorical variables, encoding 1 as ‘controls’, and 2 as ‘cases’.\n\n\n\n\n1.3.4 Step 2: Variants extraction\nAll the curated VCF files have been downloaded and processed by Email Cartagene. Preprocessing details are reported here6\n\n1.3.4.1 a) HDAC-family\n\n1.3.4.1.1 i) Retrieve HDAC positions\n\nObjective: extract the annotated VCF, for the 6 HDAC genes identified of interest, on chromosome 7 (see Section 1.3.4.1 for Bash commands).\nMethods:\n\n\nWe retrieve positions of the HDAC genes (HDAC 4, 5, 6, 7, 9 and 10) on the latest Hg38 Genome Build with script Listing 1.4. HDAC positions are reported in Table 1.77\n\nWhen several start and end positions were reported for the same gene, we consider the overall min starting position, and the max end position, respectively.\n\n\nCodetxdb &lt;- GenomicFeatures::makeTxDbFromUCSC(genome = \"hg38\", tablename = \"refGene\")\nAnnotationDbi::saveDb(txdb, \"./data/genome_builds/human_gencode_v42.sqlite\")\n\n\n\n\n\nListing 1.4: Use AnnotationDBI to fetch and retrieve automatically start and end positions of the HDAC family.\n\nhdac_genes &lt;- c(\"HDAC4\", \"HDAC5\", \"HDAC6\", \"HDAC7\", \"HDAC9\", \"HDAC10\")\n\n## Convert HGNC symbols to Entrez IDs with org.Hs.eg.db\n## 1-1 mapping, great!!\nhdac_entrez_ids &lt;- AnnotationDbi::mapIds(org.Hs.eg.db, keys = hdac_genes,\n                     column = \"ENTREZID\", keytype = \"SYMBOL\", multiVals = \"first\")\nhdac_entrez_ids &lt;- tibble::tibble(\n  HGNC_SYMBOL = names(hdac_entrez_ids),\n  GENEID = hdac_entrez_ids)\n\n## retrieve start and end positions of hdac chromosoms\ntxdb &lt;- AnnotationDbi::loadDb(\"data/genome_builds/human_gencode_v42.sqlite\")\nhdac_coords &lt;- AnnotationDbi::select(txdb,\n                     keys = hdac_entrez_ids$GENEID,\n                     columns = c(\"TXCHROM\", \"TXSTART\", \"TXEND\"),\n                     keytype = \"GENEID\")\n\n## take the min and max positions for all chromosomes\nhdac_coords &lt;- hdac_coords |&gt;\n  dplyr::group_by(GENEID, TXCHROM) |&gt;\n  dplyr::summarise(TXSTART=min(TXSTART), TXEND=max(TXEND)) |&gt;\n  dplyr::ungroup() |&gt;\n  dplyr::inner_join(hdac_entrez_ids, by = \"GENEID\") |&gt;\n  dplyr::arrange(GENEID) |&gt;\n  relocate(HGNC_SYMBOL)\nreadr::write_csv(hdac_coords,\n                 \"data/gene_positions/hdac_coords.csv\")\n\n## hdac_coords &lt;- readr::read_csv(\"data/gene_positions/hdac_coords.csv\", \n##                               show_col_types = FALSE)\nflextable(hdac_coords) |&gt; \n  bold(bold = TRUE, part = \"header\")\n\n\n\n\n\n\n\n\n\n\nHGNC_SYMBOL\nGENEID\nTXCHROM\nTXSTART\nTXEND\n\n\n\nHDAC6\n10013\nchrX\n48,801,398\n48,824,982\n\n\nHDAC5\n10014\nchr17\n44,076,753\n44,123,641\n\n\nHDAC7\n51564\nchr12\n47,782,724\n47,819,903\n\n\nHDAC10\n83933\nchr22\n50,245,184\n50,251,265\n\n\nHDAC9\n9734\nchr7\n18,086,825\n19,002,414\n\n\nHDAC4\n9759\nchr2\n239,048,168\n239,401,649\n\n\n\n\n\n\n\nTable 1.7: HDAC Gene Positions\n\n\n\n\nRemark: Instead of fetching start and end locations automatically, add an INFO/GENE field directly within the VCF files.\n\n1.3.4.1.2 ii) Extract SNPs corresponding to provided HDAC gene\n\n\nInputs:\n\nCleaned VCF file of the chromosome 7 (where HDAC-9 is present)8.\n\n\n\nOutputs:\n\n\nchr7.HDAC9.vcf: VCF file, restrained to HDAC9 region with affiliated SNPs.\n\n\n\nObjective: Extract annotated SNPs within HDAC9 boundaries, as defined by the hg38 reference genome. Details:\n\nDiscard variants with Minor Allele Frequency (MAF) \\(&lt; 0.01\\) (in other words, the SNP must be present in at least \\(1\\%\\) of the samples).\nSNPs were extracted using bcftools view, with shell script extract_variants.sh9:\n\n\n\nnohup ./shell/extract_variants.sh &gt; shell/extract_variants.log 2&gt;&1 &\n\n\nRemark: --maf guarantees removal of highly recessive SNPs, present in less than \\(1\\%\\) of cases with respect to the dominant form: infrequent SNPs are indeed associated with lower statistical power.\n\n\n1.3.5 Step 3: GWAS Analyses\n\n1.3.5.1 i) GLM and GWAS\n\nObjective: Use of PLINK2 + glm with the first 10 principal components as covariates, see Listing 1.5, using logistic regression for categorical variables, and lm for continuous outcomes.\n\nInput:\n\n\nVCF file on the region/gene of interest\nPhenotypes, with individual patient IDs.\nExplanatory variable to predict, provided with --pheno-name &lt;response_variable&gt;.\n\n\n\n\n\nListing 1.5\n\nTemplate GLM instruction for GWAS studies:\n\nplink2 \\\n1  --double-id \\ #\n2  --pheno ./phenotypes/merge_phenos_PCs.txt \\ #\n  --pheno-name OSTEOPONIA \\ #\n  --vcf /mnt/projects_tn01/Cartagene/analyses/variants_extraction/chr7.merged.clean.noMono.extracted_variants.HDAC9.vcf dosage=HDS #\n3  --glm hide-covar \\ #\n  --covar /mnt/projects_tn01/Cartagene/analyses/phenotypes/merge_phenos_PCs.txt \\ #\n  --covar-name PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10 \\ #\n4  --out HDAC9_OSTEOPONIA #\n\n1\n\nThe --double-id option ensures independent GWAS analyses per individual, aka the single-sample mode, stating explicitly that the VCF file follows a family-based format (FID/IID pairs).\n\n2\n\nGWAS inputs: We need the phenotype information (provided with --pheno and --keep commands), the variable to predict (provided with --pheno-name) and the VCF file (command --vcf), here using the SNPs annotations for the HDAC9 gene10.\n\n3\n\nGWAS model options: --glm is the general linear model, which uses by default a logistic regression for categorical variables, and a standard linear Gaussian model, equivalent to lm for continuous variables11. --covar is the covariate file, with relevant explanatory variables to integrate reported with --covar-name (see @ for details). PCAs are used to describe the population structure in an unsupervised manner; and avoid and detect latent subgroups.\n\n4\n\nThe output GWAS folder, with --out command. Stored for now in /mnt/projects_tn01/Cartagene/analyses/association.\n\n\n\n\n\nIn practice, run the plink2_gwas.sh script in the background (possibility to customise gene name and feature variables to regress on):\n## Run the GWAS pipeline in the background,\n## persist after logout, and log everything.\n\nnohup ./shell/plink2_gwas.sh &gt; shell/plink2_gwas.log 2&gt;&1 &\n\nRemark 1: you may come up with Error: Cannot proceed with --glm regression on phenotype 'TACAIX', since variance inflation factor for covariate 'PC2' is too high. In this case, you may try removing completely covariates (with --glm allow-no-covars), or/and increase variance inflation threshold (--vif number_vif option)12\nRemark 2: All the pre-processing operations detailed in Section 1.3.2.2 are only used for the computation of the PCA components, but not subsequently used in the glm regression for trimming strongly correlated features.\nRemark 3: Add phenotype covariates, such as SEX or AGE in the regression framework, which can play a strong leverage on the impact of SNPs. GENESIS is a R package mixing environmental and genetic factors in a fixed linear model approach.\n\n1.3.5.2 ii) GWAS Visualisations\nFor each gene-phenotype pair, we generate cognate Manhattan plots13, and \\(p\\)-values distributions, using histograms14, and QQplots15. Core function for generating these 3 GWAS visualisations is generate_gwas_per_phenotype. An example for gene HDAC-9 is provided in Figure 1.3.\n\nCode## p-value adjustment\n## genename &lt;- \"HDAC-9\"; pheno_label &lt;- \"OSTEOPONIA\"; filedate &lt;- \"2025-04-07\"\nnum_variants &lt;- readr::read_csv(\"./tables/HDAC-9/HDAC-9_AVCGLOBAL_PRE_M_2025-04-07.AVCGLOBAL_PRE_M.glm.logistic.hybrid\", show_col_types = FALSE) |&gt; nrow()\npval_threshold &lt;- 0.05/(num_variants*length(cartagene_response_variables$Features))\n## pval_threshold &lt;- 0.01/num_variants\n\ngwas_plots_hdac &lt;- lapply(cartagene_response_variables$Features, \n                          function(feature_label) generate_gwas_per_phenotype (genename = \"HDAC-9\",\n                                                                               pheno_label = feature_label, filedate = \"2025-04-07\", pval_threshold = pval_threshold)) \n\ngwas_plots_hdac &lt;- gridExtra::marrangeGrob(gwas_plots_hdac, nrow=1, ncol=1)\n\nggsave(\"figures/gwas_HDAC9.pdf\",\n       gwas_plots_hdac, dpi = 600,\n       width = 8, height = 12) \n\n\n\n\nDownload PDF file.\n\n\nFigure 1.3\n\n\n\nCodegwas_results &lt;- readr::read_tsv(\"./tables/HDAC-9/HDAC-9_OSTEOPONIA_2025-04-07.OSTEOPONIA.glm.logistic.hybrid\",\n                                show_col_types = FALSE) \n\nggplot(gwas_results, aes(x = OR)) +\n  geom_histogram(binwidth = 0.05) +\n  # geom_freqpoly()\n  # geom_density(adjust = 200, col = \"red\") +\n  # scale_x_continuous(breaks = seq(0, 1, by = 0.05), limits = c(0, 0.5)) +\n  theme_minimal() +\n  labs(title = \"Density plot of the OR (Odds Ratio) for variable `OSTEOPONIA`, and gene `HDAC-9`\", \n       x =  \"Odds Ratio.\")\n\n\n\n\n\n\nFigure 1.4: Density plot of the OR (Odds Ratio) for variable OSTEOPONIA, and gene HDAC-9.\n\n\n\n\n\n1.3.5.3 iii) Multiple test correction\nTo compute the adjusted significance threshold, we applied a FWER-like approach, conventional in the GWAS field: {r} 0.05/(num_variants*length(cartagene_response_variables$Features)), in which you divide the pre-defined threshold (standard: 0.05) by the total number of pairwise tests carried out (number of variants times number of regression variables times). Final threshold is accordingly: 2.1188236^{-6}, as 2622 variants were extracted, and 9 phenotype variables were predicted.\nThe FWER approach is particularly conservative, in other words, only the most significant differences are detected.\n\n\nPerspectives:\n\n\nRecent Adjusted \\(p\\)-value correction method.\n\nMultiple Comparisons Using R, comprehensive resource of distinct R package strategies for correcting for multiplicity of \\(p\\)-values, from Bretz, Hothorn, and Westfall (2016). Report also to Note 1.1 for an overview of existing approaches.\n\nMultiple Testing: Methods Overview reviews the most popular approaches for controlling the false-error rate, while providing practical R code snippets to implement them. The blog concludes on the prevalance of the Benjamini-Yekuiteli approach, offering the best compromise between statistical power and interpretability.\n\n\n\n\n\n\n\n\n\nNote 1.1: Classes of Multiple Test correction approaches\n\n\n\n\n\nMultiple comparison procedures (MCPs) can be classified into the following adjustment methods:\n\nFixed sequential: no adjustment as long as H0s are rejected. One non-rejection and it stops testing with all others non-rejected.\nCallback: significance level (e.g. 0.05) is split between all hypotheses (can be further weighted). With rejection of the subsequent H0s, their fractions of significance level is accumulated and passed to the next comparison.\nGatekeeper: serial, parallel & combined trees, collecting hypotheses into families. Groups of testing can be interpreted as gatekeepers: only if any \\(H_0\\) in a family is rejected that the significance is propagated to the next family. The approach is the most versatile, and can be flexibly implemented in R package gMCPLite. See also Graphical Approaches to Multiple Test Problems, for additional details.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Main GWAS pipeline</span>"
    ]
  },
  {
    "objectID": "CARTaGENE-GWAS-Report.html#perspectives",
    "href": "CARTaGENE-GWAS-Report.html#perspectives",
    "title": "\n1  Main GWAS pipeline\n",
    "section": "\n1.4 Perspectives",
    "text": "1.4 Perspectives\n\n1.4.1 Post-hoc GWAS\n\nCollect information on variants with LLM-like VarChat app\n\n1.4.2 Explore non-coding and regulatory regions (from WES to WGS)\n\nPaper Systematic differences in discovery of genetic effects on gene expression and complex traits, from Mostafavi et al. (2023), suggest extending extraction of genomic regions of interest beyond coding sequences (report to Section 1.3.4 for current approach). Indeed, the article demonstrates that most of identified signals originate from nearby gene regulatory sites.\nEPInformer: a scalable deep learning framework for gene expression prediction by integrating promoter-enhancer sequences with multimodal epigenomic data, from Lin, Luo, and Pinello (2024). Avalaible as a GH package. Can infer and predict gene expression from promoter and enhancer sequences paired with epigenomic signals; identify the most significant enhancers; and identify regulatory sequences and transcription factor binding motifs.\nAutomatically extract and annotate variants, based on their locations, using VariantAnnotation::locateVariants() function. Variants annotations notably encompass coding, UTRs, introns and promoters.\n\n1.4.3 Post-GWAS: Explore other types of genetic variations\nThe most typical mutations included in GWAS studies are Single Nucleotide Polymorphisms (SNPs), and occasionally small indels. Beyond them, we could have considered Structural Variants (SVs): large insertions, deletions, duplications, inversions, translocations, Copy Number Variations (CNVs): gains or losses of large DNA segments, Microsatellites and Epigenetic changes in regulatory regions.\n\nGenome-wide association testing beyond SNPs, from Harris et al. (2025)\nBenchmarking post-GWAS analysis tools in major depression: Challenges and implications, from Pérez-Granado, Piñero, and Furlong (2022).\nThe VariantAnnotation::predictCoding computes amino acid coding changes for non-synonymous variants, while the SIFT and PolyPhen web databases evaluate the impact of SNP substitution, based on the predicted level of changes of the 3D-protein reconfiguration.\n\n1.4.4 Post-GWAS: Retrieve automatically variants of interest\nThis analysis is not formally a GWAS study, but rather a gene-centric study, pre-selecting genes based on prior knowledge and/or intuition.\nAlternatively, we could consider a data-driven, and more agnostic approach, to refine the selection of gene candidates. Several approaches to that end have been implemented:\n\nGnanaolivu et al. (2025) proposed in A clinical knowledge graph-based framework to prioritize candidate genes for facilitating diagnosis of Mendelian diseases and rare genetic conditions, the phenotype prioritization and analysis for rare diseases, PPAR algorithm to rank genes based on human phenotype ontology (HPO) terms.16. In details, PPAR combines embeddings from the human knowledge graph, incorporating genes, HPO terms, and gene ontology annotations connections. For each input HPO term, a prioritized list of genes is returned based on their relevance and similarity to the HPO term.\nBridges et al. (2025) developed in Towards a standard benchmark for phenotype-driven variant and gene prioritisation algorithms: PhEval, Phenotypic inference Evaluation framework a unified benchmarking platform to clean inputs for phenotype-driven VGPAs. Variant and Gene Prioritisation Algorithms integrate complex and multi-modal datasets, such as ontologies and gene-to-phenotype associations, to predict the most influential and promising gene targets controlling the evolution of rare diseases. Model is available as GitHub Repo PhEval.\n\n1.4.5 Post-GWAS: Incorporate familial pedigrees\nAn alternative to candidate gene association studies relies on linkage analysis, which uses familial pedigrees to map genetic variants underlying common human diseases. This strategy requires both genetic data and detailed family pedigrees.\n\nGenome-wide association study of fat content and fatty acid composition of shea tree., from Attikora et al. (2025). Under the hood, relies on the mrMLM R package to include both the population structure matrix and the kinship matrix. Provides a complete GWAS pipeline, including a number of meaningful illustrations.\nBHCox: Bayesian heredity-constrained Cox proportional hazards models for detecting gene-environment interactions, from Sun et al. (2025). Under the hood, relies on the brms R package.\n\n1.4.6 Post-GWAS: Polygenic risk scores\n\nOptimizing and benchmarking polygenic risk scores with GWAS summary statistics, from Z. Zhao et al. (2024).\nXPRS: A Tool for Interpretable and Explainable Polygenic Risk Score, from Kim and Lee (2025), is a R package for inferring the polygenic risk score for assessing genetic susceptibility to diseases, providing additional interpretation and visualisation tools. PRSs are further split and classified into genes and single nucleotide polymorphism (SNP) contribution scores via Shapley additive explanations (SHAPs), visualised as Manhattan plots, LocusZoom-like plots and tables at the population and individual levels.\nPNL: a software to build polygenic risk scores using a Super Learner approach based on PairNet, a Convolutional Neural Network, from Chen et al. (2025).\n\n1.4.7 Post-GWAS: Orthogonal integration\n\n1.4.7.1 Epigenomic\n\n\nG. Zhao and Lai (2025) implements SC-VAR: a computational tool for interpreting polygenic disease risks using single-cell epigenomic data, a novel computational tool available as a GitHub repo and Python application: SC-VAR GitHub. SC-VAR uses single-cell epigenomic data to predict functional outcomes of the identified disease-associated GWAS variants, enhancing their interpretability. Under the hood, relies on MAGMA linear modelling framework, developed by Leeuw et al. (2015).\n\n1.4.7.2 eQTL (quantitative expression)\n\n\nFIVEx is a web-based interface to explore CarTaGene to visualize and query eQTL (quantitative trait loci) data in various ways. Would need a stringent maintenance!!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Main GWAS pipeline</span>"
    ]
  },
  {
    "objectID": "CARTaGENE-GWAS-Report.html#appendix",
    "href": "CARTaGENE-GWAS-Report.html#appendix",
    "title": "\n1  Main GWAS pipeline\n",
    "section": "\n1.5 Appendix",
    "text": "1.5 Appendix\n\n1.5.1 Scalability with Nextflow\n\nLots of intermediate files are not required for downstream analyses, hence it would be relevant to rely on an existing Nextflow or Snakemake DSL workflows:\n\nnf-GWAS ‘Nextflow pipeline’, from Schönherr and Forer ([2021] 2024), is actively maintained by Curie Bioinformatics Team, and includes the latest plink2 facilities. Complementary tools include:\nThe Nextflow Seqera multiqc initiative collects within the same repository a variety of command-line tools, such as bcftools and plink2, with notably the vcftools and multivcfanalyzer modules. Note however that these tools are optimised in Python.\nPopGLen ‘Snakemake’ pipeline, from Nolen (2025). Not for running GWAS analyses, but rather for evaluating the quality and impact of preprocessing and quality mapping at the population-level genome starting from FASTQ files.\n\n1.5.2 FASTQ and FASTA Quality Controls\n\nThe 7th chapter entitled “Quality Check, Processing and Alignment of High-throughput Sequencing Reads” introduces the fundamentals, using R packages, to process FASTA reads, and evaluate their quality with a variety of metrics (\\(k\\)-mer over-representation, sequence quality, percentage of duplicated reads, ..).\n\n\n\n\n\nAttikora, Affi Jean Paul, Kouakou Alfred Kouassi, Saraka Didier Martial Yao, Dougba Noel Dago, Souleymane Silué, Caroline De Clerck, Nafan Diarrassouba, et al. 2025. ‘Genome-Wide Association Study of Fat Content and Fatty Acid Composition of Shea Tree (Vitellaria Paradoxa C.F. Gaertn Subsp. Paradoxa)’. BMC Genomics 26 (1): 164. https://doi.org/10.1186/s12864-025-11344-z.\n\n\nAwadalla, Philip, Catherine Boileau, Yves Payette, Youssef Idaghdour, Jean-Philippe Goulet, Bartha Knoppers, Pavel Hamet, Claude Laberge, and on behalf of the CARTaGENE Project. 2013. ‘Cohort Profile of the CARTaGENE Study: Quebec’s Population-Based Biobank for Public Health and Personalized Genomics’. International Journal of Epidemiology 42 (5): 1285–99. https://doi.org/10.1093/ije/dys160.\n\n\nBretz, Frank, Torsten Hothorn, and Peter Westfall. 2016. Multiple Comparisons Using R. New York: Chapman and Hall/CRC. https://doi.org/10.1201/9781420010909.\n\n\nBridges, Yasemin, Vinicius de Souza, Katherina G. Cortes, Melissa Haendel, Nomi L. Harris, Daniel R. Korn, Nikolaos M. Marinakis, et al. 2025. ‘Towards a Standard Benchmark for Phenotype-Driven Variant and Gene Prioritisation Algorithms: PhEval - Phenotypic Inference Evaluation Framework’. BMC Bioinformatics 26 (1): 87. https://doi.org/10.1186/s12859-025-06105-4.\n\n\nChen, Ting-Huei, Chia-Jung Lee, Syue-Pu Chen, Shang-Jung Wu, and Cathy S J Fann. 2025. ‘PNL: A Software to Build Polygenic Risk Scores Using a Super Learner Approach Based on PairNet, a Convolutional Neural Network’. Bioinformatics 41 (2): btaf071. https://doi.org/10.1093/bioinformatics/btaf071.\n\n\nDavid, Susana. 2021. ‘A Current Guide to Candidate Gene Association Studies’. Trends in Genetics 37 (12): 1056–59. https://doi.org/10.1016/j.tig.2021.07.009.\n\n\nGnanaolivu, Rohan, Gavin Oliver, Garrett Jenkinson, Emily Blake, Wenan Chen, Nicholas Chia, Eric W. Klee, and Chen Wang. 2025. ‘A Clinical Knowledge Graph-Based Framework to Prioritize Candidate Genes for Facilitating Diagnosis of Mendelian Diseases and Rare Genetic Conditions’. BMC Bioinformatics 26 (1): 82. https://doi.org/10.1186/s12859-025-06096-2.\n\n\nHarris, Laura, Ellen M. McDonagh, Xiaolei Zhang, Katherine Fawcett, Amy Foreman, Petr Daneck, Panagiotis I. Sergouniotis, et al. 2025. ‘Genome-Wide Association Testing Beyond SNPs’. Nature Reviews Genetics 26 (3): 156–70. https://doi.org/10.1038/s41576-024-00778-y.\n\n\nHayes, Ben. 2013. ‘Overview of Statistical Methods for Genome-Wide Association Studies (GWAS)’. In Genome-Wide Association Studies and Genomic Prediction, edited by Cedric Gondro, Julius van der Werf, and Ben Hayes, 149–69. Totowa, NJ: Humana Press. https://doi.org/10.1007/978-1-62703-447-0_6.\n\n\nKim, Na Yeon, and Seunggeun Lee. 2025. ‘XPRS: A Tool for Interpretable and Explainable Polygenic Risk Score’. Bioinformatics, March, btaf143. https://doi.org/10.1093/bioinformatics/btaf143.\n\n\nLeeuw, Christiaan A. de, Joris M. Mooij, Tom Heskes, and Danielle Posthuma. 2015. ‘MAGMA: Generalized Gene-Set Analysis of GWAS Data’. PLOS Computational Biology 11 (4): e1004219. https://doi.org/10.1371/journal.pcbi.1004219.\n\n\nLin, Jiecong, Ruibang Luo, and Luca Pinello. 2024. ‘EPInformer: A Scalable Deep Learning Framework for Gene Expression Prediction by Integrating Promoter-Enhancer Sequences with Multimodal Epigenomic Data’. 1 August 2024. https://doi.org/10.1101/2024.08.01.606099.\n\n\nMostafavi, Hakhamanesh, Jeffrey P. Spence, Sahin Naqvi, and Jonathan K. Pritchard. 2023. ‘Systematic Differences in Discovery of Genetic Effects on Gene Expression and Complex Traits’. Nature Genetics 55 (11): 1866–75. https://doi.org/10.1038/s41588-023-01529-1.\n\n\nNolen, Zachary J. 2025. ‘PopGLen—A Snakemake Pipeline for Performing Population Genomic Analyses Using Genotype Likelihood-Based Methods’. Bioinformatics, March, btaf105. https://doi.org/10.1093/bioinformatics/btaf105.\n\n\nPelletier, Justin. 2022. ‘Évaluation de l’imputation Des Données Génétiques Canadiennes-Françaises’, April. http://hdl.handle.net/1866/27582.\n\n\nPérez-Granado, Judith, Janet Piñero, and Laura I. Furlong. 2022. ‘Benchmarking Post-GWAS Analysis Tools in Major Depression: Challenges and Implications’. Frontiers in Genetics 13 (October). https://doi.org/10.3389/fgene.2022.1006903.\n\n\nSchönherr, Sebastian, and Lukas Forer. (2021) 2024. ‘Nf-Gwas - A Nextflow Pipeline to Perform GWAS.’ https://github.com/genepi/nf-gwas.\n\n\nSun, Na, Qiang Han, Yu Wang, Mengtong Sun, Ziqing Sun, Hongpeng Sun, and Yueping Shen. 2025. ‘BHCox: Bayesian Heredity-Constrained Cox Proportional Hazards Models for Detecting Gene-Environment Interactions’. BMC Bioinformatics 26 (1): 58. https://doi.org/10.1186/s12859-025-06077-5.\n\n\nUffelmann, Emil, Qin Qin Huang, Nchangwi Syntia Munung, Jantina de Vries, Yukinori Okada, Alicia R. Martin, Hilary C. Martin, Tuuli Lappalainen, and Danielle Posthuma. 2021. ‘Genome-Wide Association Studies’. Nature Reviews Methods Primers 1 (1): 1–21. https://doi.org/10.1038/s43586-021-00056-9.\n\n\nWang, William Y. S., Bryan J. Barratt, David G. Clayton, and John A. Todd. 2005. ‘Genome-Wide Association Studies: Theoretical and Practical Concerns’. Nature Reviews Genetics 6 (2): 109–18. https://doi.org/10.1038/nrg1522.\n\n\nYang, Zikun, Basilio Cieza, Dolly Reyes-Dumeyer, Rosa Montesinos, Marcio Soto-Añari, Nilton Custodio, and Giuseppe Tosto. 2024. ‘A Benchmark Study on Current GWAS Models in Admixed Populations’. Briefings in Bioinformatics 25 (1): bbad437. https://doi.org/10.1093/bib/bbad437.\n\n\nZhao, Gefei, and Binbin Lai. 2025. ‘SC-VAR: A Computational Tool for Interpreting Polygenic Disease Risks Using Single-Cell Epigenomic Data’. Briefings in Bioinformatics 26 (2): bbaf123. https://doi.org/10.1093/bib/bbaf123.\n\n\nZhao, Zijie, Tim Gruenloh, Meiyi Yan, Yixuan Wu, Zhongxuan Sun, Jiacheng Miao, Yuchang Wu, Jie Song, and Qiongshi Lu. 2024. ‘Optimizing and Benchmarking Polygenic Risk Scores with GWAS Summary Statistics’. Genome Biology 25 (1): 260. https://doi.org/10.1186/s13059-024-03400-w.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Main GWAS pipeline</span>"
    ]
  },
  {
    "objectID": "CARTaGENE-GWAS-Report.html#footnotes",
    "href": "CARTaGENE-GWAS-Report.html#footnotes",
    "title": "\n1  Main GWAS pipeline\n",
    "section": "",
    "text": "Comprehensive Introduction section reviewing the most critical challenges when coping with GWAS.↩︎\nNotably includes MHC, lactase region, and known inversions 8p23 and 17q21.31.↩︎\n--king-cutoff 0.0884 corresponds to PI_HAT = 0.125, see details here↩︎\nDMOTSCORE_mod represents the measurement of bone mineral density at the calcaneus. While no universally accepted threshold exists for the diagnosis of osteopenia or osteoporosis, we adopt the conventional cut-off of -1.5.↩︎\nFor both FXMOF_POST and FXALL_POST, the dates of occurrence and censoring dates are available in FXALL_POSTDATE and FXMOF_POSTDATE respectively.↩︎\nUse of dnaseq Genpipes pipelines, run on Compute Canada Clusters, version 3.1.5.↩︎\nAvoid using BiomarT package a tall costs: it’s not anymore maintained, and leveraged out-of-date Hg37 Human Genome Build. Report to Genome Builds Versions for details.↩︎\nAll curated VCF files per chromosome are stored in ./data/genotypages/ (linked symbolically with /mnt/projects_tn01/Cartagene/genotypage/imputation/imputation_merged).↩︎\nnohup option combined with & character enables running variants extraction in the background, even with terminal disrupting and closing.↩︎\ndosage=HDS, for Hard Dosage, provides the instruction describing genotype uncertainties for enhanced statistical power. It’s particularly useful when working as here with imputed genotypes, where part of the SNPs were inferred using reference panels.↩︎\nThe hide-covar option runs GLM, but doesn’t output covariate results. Besides, note that --covar passes quantitative covariates (e.g., age, PCs), while --ide-covar passes categorical covariates↩︎\nNote that a VIF factor above 10 is considered problematic as it can significantly distort regression estimates. Discussion and visualisations on VIF influence. Briefly, VIF quantifies the degree of similarity across predictor variables, as the GLM-family usually assumes independence between explanatory variables. When VIF is significant, independence assumption is discarded, which might be explained by the fact that preprocessing in Section 1.3.2.2 for removing correlated SNps and individuals are not used in subsequent GWAS differential downstream analyses.↩︎\nMore customisation available in Manhattan plot in R: a review↩︎\nHow to interpret a \\(p\\)-value histogram↩︎\nHow I Make QQ Plots Using ggplot2?↩︎\nNote that relying on HPO terms, for example, HP:0004322 – Osteopenia, would alleviate the need for standardising phenotype labels, using universally acknowledged scientific terms instead.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Main GWAS pipeline</span>"
    ]
  }
]